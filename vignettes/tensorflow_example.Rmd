---
title: "Training a TensorFlow Model on MNIST"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Training a TensorFlow Model on MNIST}
  %\VignetteEngine{knitr::rmarkdown}
  \use_package{UTF-8}
---

This article demonstrates how to run a TensorFlow training script at scale using AzureML SDK for R. We will train a TensorFlow model to classify handwritten digits using a deep neural network (DNN) and log our results to the Azure Machine Learning service.

## 1. Set up the experiment

Let's prepare for training by loading the required package, initializing a workspace, and creating an experiment.

### Import package
```R
library("azureml")
```

### Initialize a workspace

The `Workspace` is the top-level resource for the service. It provides us with a centralized place to work with all the artifacts we will create. 

You can create a `Workspace` object from a local `config.json` file
```R
ws <- load_workspace_from_config()
```

Or load an existing workspace from your Azure Machine Learning account
```R
ws <- get_workspace("<your workspace name>", "<your subscription ID>", "<your resource group>")
```

### Create a deep learning experiment

For this example, we will create an `Experiment` called "tf-mnist".

```R
exp <- Experiment(workspace = ws, name = 'tf-mnist')
```

## 2. Create a compute target

Now, we will create a compute target for our TensorFlow job to run on. In this example, we are creating a CPU-enabled compute cluster.
```R
cluster_name <- "rcluster"

compute_target <- get_compute(ws, cluster_name = cluster_name)
if (is.null(compute_target))
{
  vm_size <- "STANDARD_D2_V2"
  compute_target <- create_aml_compute(workspace = ws, cluster_name = cluster_name,
                                       vm_size = vm_size, max_nodes = 1)
}

wait_for_provisioning_completion(compute_target)
```

## 3. Prepare training script

In order to collect and upload run metrics, we need to import the `azureml` package at the top of our training script, ["tf_mnist.R"](../../samples/training/train-with-tensorflow/tf_mnist.R).

```R
library("azureml")
```

Then, we need to add the `log_metric_to_run` function to track our primary metric,  "accuracy", for this experiment. If you have your own training script with several important metrics, simply create a logging call for each one within the script.

```R
current_run <- get_current_run()
log_metric_to_run("accuracy",
                  sess$run(accuracy,
                  feed_dict = dict(x = mnist$test$images, y_ = mnist$test$labels)),
                  current_run)
```

## 4. Create an estimator

An `Estimator` offers a simple way to launch a training job on a compute target. Our training script will need the TensorFlow package to run, and we can have it installed in the Docker container where our job will run by passing the package name to the `cran_packages` parameter.

```R
est <- estimator(source_directory = ".",
                 entry_script = "tf_mnist.R",
                 compute_target = compute_target,
                 cran_packages = c("tensorflow"))
```

## 5. Submit a run

Submitting our experiment will return a `Run` object that we will use to interface with the run history during and after the job.

```R
run <- submit_experiment(est, exp)
wait_for_run_completion(run, show_output = TRUE)
```

### 6. View metrics

Finally, we can view the metrics collected during our TensorFlow run!

```R
metrics <- get_run_metrics(run)
metrics
```
