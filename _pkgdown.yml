navbar:
  title: ~
  type: default
  left:
  - icon: fa-home
    href: index.html
  - text: Reference
    href: reference/index.html
  - text: Articles
    menu:
    - text: Install the Azure ML SDK for R
      href: articles/installation.html
    - text: Set up an Azure ML workspace
      href: articles/configuration.html
    - text: Train and deploy your first model with Azure ML
      href: articles/train-and-deploy-first-model.html
    - text: Train a TensorFlow model
      href: articles/train-with-tensorflow.html
    - text: Hyperparameter tune a Keras model
      href: articles/hyperparameter-tune-with-keras.html
    - text: Deploy a web service to Azure Kubernetes Service
      href: articles/deploy-to-aks.html
    - text: ---
    - text: Guides
    - text: Deploying models
      href: articles/deploying-models.html
    - text: Troubleshooting
      href: articles/troubleshooting.html
  - text: News
    href: news/index.html

reference:
- title: Installation
  desc:
  contents:
  - '`install_azureml`'
- title: Workspaces
  desc: Functions for managing workspace resources. A **Workspace** is the top-level resource for Azure Machine Learning. It provides a centralized place to work with all the artifacts you create when you use Azure ML.
  contents:
  - '`create_workspace`'
  - '`get_workspace`'
  - '`service_principal_authentication`'
  - '`load_workspace_from_config`'
  - '`write_workspace_config`'
  - '`get_default_datastore`'
  - '`set_default_datastore`'
  - '`delete_workspace`'
  - '`list_workspaces`'
  - '`get_workspace_details`'
  - '`get_default_keyvault`'
  - '`set_secrets`'
  - '`get_secrets`'
  - '`delete_secrets`'
  - '`list_secrets`'
  - '`service_principal_authentication`'
  - '`interactive_login_authentication`'
- title: Compute targets
  desc: Functions for managing compute resources. A **Compute Target** is a designated compute resource where you run your scripts or host your service deployments. Compute targets make it easy to change your compute environment without changing your code. Supported compute target types in the R SDK include `AmlCompute` and `AksCompute`.
  contents:
  - '`create_aml_compute`'
  - '`list_nodes_in_aml_compute`'
  - '`update_aml_compute`'
  - '`create_aks_compute`'
  - '`get_aks_compute_credentials`'
  - '`attach_aks_compute`'
  - '`detach_aks_compute`'
  - '`get_compute`'
  - '`wait_for_provisioning_completion`'
  - '`list_supported_vm_sizes`'
  - '`delete_compute`'
- title: Working with data
  desc: Functions for accessing your data in Azure Storage services. A **Datastore** is attached to a workspace and is used to store connection information to an Azure storage service.
  contents:
  - '`upload_files_to_datastore`'
  - '`upload_to_datastore`'
  - '`download_from_datastore`'
  - '`get_datastore`'
  - '`register_azure_blob_container_datastore`'
  - '`register_azure_file_share_datastore`'
  - '`register_azure_sql_database_datastore`'
  - '`register_azure_postgre_sql_datastore`'
  - '`register_azure_data_lake_gen2_datastore`'
  - '`unregister_datastore`'
- title: Working with datasets
  desc: Functions for managing datasets. An Azure Machine Learning **Dataset** allows you to interact with data in your datastores and package your data into a consumable object for machine learning tasks. Datasets can be created from local files, public urls, or specific file(s) in your datastores. Azure ML supports Dataset types of `FileDataset` and `TabularDataset`.
  contents:
  - '`register_dataset`'
  - '`unregister_all_dataset_versions`'
  - '`get_dataset_by_name`'
  - '`get_dataset_by_id`'
  - '`get_input_dataset_from_run`'
  - '`create_file_dataset_from_files`'
  - '`get_file_dataset_paths`'
  - '`download_from_file_dataset`'
  - '`mount_file_dataset`'
  - '`skip_from_dataset`'
  - '`take_from_dataset`'
  - '`take_sample_from_dataset`'
  - '`random_split_dataset`'
  - '`create_tabular_dataset_from_parquet_files`'
  - '`create_tabular_dataset_from_delimited_files`'
  - '`create_tabular_dataset_from_json_lines_files`'
  - '`create_tabular_dataset_from_sql_query`'
  - '`drop_columns_from_dataset`'
  - '`keep_columns_from_dataset`'
  - '`filter_dataset_after_time`'
  - '`filter_dataset_before_time`'
  - '`filter_dataset_between_time`'
  - '`filter_dataset_from_recent_time`'
  - '`define_timestamp_columns_for_dataset`'
  - '`load_dataset_into_data_frame`'
  - '`convert_to_dataset_with_csv_files`'
  - '`convert_to_dataset_with_parquet_files`'
  - '`data_type_bool`'
  - '`data_type_datetime`'
  - '`data_type_double`'
  - '`data_type_long`'
  - '`data_type_string`'
  - '`promote_headers_behavior`'
  - '`data_path`'
  - '`dataset_consumption_config`'
- title: Environments
  desc: Functions for managing environments. An Azure Machine Learning **Environment** allows you to create, manage, and reuse the software dependencies required for training and deployment. Environments specify the R packages, environment variables, and software settings around your training and scoring scripts for your containerized training runs and deployments. They are managed and versioned entities within your Azure ML workspace that enable reproducible, auditable, and portable machine learning workflows across different compute targets. For more details, see `r_environment()`.
  contents:
  - '`r_environment`'
  - '`register_environment`'
  - '`get_environment`'
  - '`container_registry`'
- title: Training & experimentation
  desc: Functions for managing experiments and runs. An **Experiment** is a grouping of the collection of runs from a specified script. A **Run** represents a single trial of an experiment. A run is the object used to monitor the asynchronous execution of a trial, log metrics and store output of the trial, and to analyze results and access artifacts generated by the trial. The following run types are supported - `ScriptRun` (for Estimator experiments) and `HyperDriveRun` (for HyperDrive experiments). For functions that are specific only to HyperDriveRuns, see the **Hyperparameter tuning** reference sections. An **Estimator** wraps run configuration information for specifying details of executing an R script. Running an Estimator experiment (using `submit_experiment()`) will return a `ScriptRun` object and execute your training script on the specified compute target.
  contents:
  - '`experiment`'
  - '`get_runs_in_experiment`'
  - '`submit_experiment`'
  - '`wait_for_run_completion`'
  - '`estimator`'
  - '`start_logging_run`'
  - '`complete_run`'
  - '`get_current_run`'
  - '`get_run`'
  - '`get_run_details`'
  - '`get_run_details_with_logs`'
  - '`get_run_metrics`'
  - '`get_secrets_from_run`'
  - '`cancel_run`'
  - '`get_run_file_names`'
  - '`download_file_from_run`'
  - '`download_files_from_run`'
  - '`upload_files_to_run`'
  - '`upload_folder_to_run`'
  - '`log_metric_to_run`'
  - '`log_accuracy_table_to_run`'
  - '`log_confusion_matrix_to_run`'
  - '`log_image_to_run`'
  - '`log_list_to_run`'
  - '`log_predictions_to_run`'
  - '`log_residuals_to_run`'
  - '`log_row_to_run`'
  - '`log_table_to_run`'
  - '`plot_run_details`'
  - '`cran_package`'
- title: Hyperparameter tuning
  desc: Functions for configuring and managing hyperparameter tuning (HyperDrive) experiments. Azure ML's HyperDrive functionality enables you to automate hyperparameter tuning of your machine learning models. For example, you can define the parameter search space as discrete or continuous, and a sampling method over the search space as random, grid, or Bayesian. Also, you can specify a primary metric to optimize in the hyperparameter tuning experiment, and whether to minimize or maximize that metric. You can also define early termination policies in which poorly performing experiment runs are canceled and new ones started.
  contents:
  - '`hyperdrive_config`'
  - '`random_parameter_sampling`'
  - '`grid_parameter_sampling`'
  - '`bayesian_parameter_sampling`'
  - '`choice`'
  - '`randint`'
  - '`uniform`'
  - '`quniform`'
  - '`loguniform`'
  - '`qloguniform`'
  - '`normal`'
  - '`qnormal`'
  - '`lognormal`'
  - '`qlognormal`'
  - '`primary_metric_goal`'
  - '`bandit_policy`'
  - '`median_stopping_policy`'
  - '`truncation_selection_policy`'
  - '`get_best_run_by_primary_metric`'
  - '`get_child_runs_sorted_by_primary_metric`'
  - '`get_child_run_hyperparameters`'
  - '`get_child_run_metrics`'
- title: Model management & deployment
  desc: Functions for model management and deployment. Registering a model allows you to store and version your trained model in a workspace. A registered **Model** can then be deployed as a **Webservice** using Azure ML. If you would like to access all the assets needed to host a model as a web service without actually deploying the model, you can do so by packaging the model as a `ModelPackage`. You can deploy your model as a `LocalWebservice` (locally), `AciWebservice` (on Azure Container Instances), or `AksWebservice` (on Azure Kubernetes Service).
  contents:
  - '`get_model`'
  - '`register_model`'
  - '`register_model_from_run`'
  - '`download_model`'
  - '`deploy_model`'
  - '`package_model`'
  - '`delete_model`'
  - '`get_model_package_container_registry`'
  - '`get_model_package_creation_logs`'
  - '`pull_model_package_image`'
  - '`save_model_package_files`'
  - '`wait_for_model_package_creation`'
  - '`inference_config`'
  - '`get_webservice`'
  - '`wait_for_deployment`'
  - '`get_webservice_logs`'
  - '`get_webservice_keys`'
  - '`generate_new_webservice_key`'
  - '`get_webservice_token`'
  - '`invoke_webservice`'
  - '`delete_webservice`'
  - '`aci_webservice_deployment_config`'
  - '`update_aci_webservice`'
  - '`aks_webservice_deployment_config`'
  - '`update_aks_webservice`'
  - '`local_webservice_deployment_config`'
  - '`update_local_webservice`'
  - '`delete_local_webservice`'
  - '`reload_local_webservice_assets`'
  - '`resource_configuration`'
