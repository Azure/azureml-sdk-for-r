<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Create an inference configuration for model deployments — inference_config • azuremlsdk</title>

<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>



<meta property="og:title" content="Create an inference configuration for model deployments — inference_config" />

<meta property="og:description" content="The inference configuration describes how to configure the model to make
predictions. It references your scoring script (entry_script) and is
used to locate all the resources required for the deployment. Inference
configurations use Azure Machine Learning environments (see r_environment())
to define the software dependencies needed for your deployment." />
<meta name="twitter:card" content="summary" />



<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">azuremlsdk</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.5.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/cnn-tuning-with-hyperdrive/cnn-tuning-with-hyperdrive.html">Hyperparameter Tuning a Keras Model with HyperDrive</a>
    </li>
    <li>
      <a href="../articles/deploy-to-aks/deploy-to-aks.html">Deploying to AKS with Azure ML SDK for R</a>
    </li>
    <li>
      <a href="../articles/installation.html">Installing AzureML SDK for R</a>
    </li>
    <li>
      <a href="../articles/train-with-tensorflow/train-with-tensorflow.html">Training a TensorFlow Model on MNIST</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/azure/azureml-sdk-for-r">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Create an inference configuration for model deployments</h1>
    <small class="dont-index">Source: <a href='https://github.com/azure/azureml-sdk-for-r/blob/master/R/model.R'><code>R/model.R</code></a></small>
    <div class="hidden name"><code>inference_config.Rd</code></div>
    </div>

    <div class="ref-description">
    
    <p>The inference configuration describes how to configure the model to make
predictions. It references your scoring script (<code>entry_script</code>) and is
used to locate all the resources required for the deployment. Inference
configurations use Azure Machine Learning environments (see <code><a href='r_environment.html'>r_environment()</a></code>)
to define the software dependencies needed for your deployment.</p>
    
    </div>

    <pre class="usage"><span class='fu'>inference_config</span>(<span class='no'>entry_script</span>, <span class='kw'>source_directory</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>description</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>environment</span> <span class='kw'>=</span> <span class='kw'>NULL</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>entry_script</th>
      <td><p>A string of the path to the local file that contains
the code to run for making predictions.</p></td>
    </tr>
    <tr>
      <th>source_directory</th>
      <td><p>(Optional) A string of the path to the local folder
that contains the files to package and deploy alongside your model, such as
helper files for your scoring script (<code>entry_script</code>). The folder must
contain the <code>entry_script</code>.</p></td>
    </tr>
    <tr>
      <th>description</th>
      <td><p>(Optional) A string of the description to give this
configuration.</p></td>
    </tr>
    <tr>
      <th>environment</th>
      <td><p>An <code>Environment</code> object to use for the deployment. The
environment does not have to be registered.</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>The <code>InferenceConfig</code> object.</p>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    
<h3>Defining the entry script</h3>
<p>To deploy a model, you must provide an entry script that accepts requests,
scores the requests by using the model, and returns the results. The
entry script is specific to your model. It must understand the format of
the incoming request data, the format of the data expected by your model,
and the format of the data returned to clients. If the request data is in a
format that is not usable by your model, the script can transform it into
an acceptable format. It can also transform the response before returning
it to the client.</p>
<p>The entry script must contain an <code>init()</code> method that loads your model and
then returns a function that uses the model to make a prediction based on
the input data passed to the function. Azure ML runs the <code>init()</code> method
once, when the Docker container for your web service is started. The
prediction function returned by <code>init()</code> will be run every time the service
is invoked to make a prediction on some input data. The inputs and outputs
of this prediction function typically use JSON for serialization and
deserialization.</p>
<p>To locate the model in your entry script (when you load the model in the
script's <code>init()</code> method), use <code>AZUREML_MODEL_DIR</code>, an environment variable
containing the path to the model location. The environment variable is
created during service deployment, and you can use it to find the location
of your deployed model(s).</p>
<p>The following table describes the value of <code>AZUREML_MODEL_DIR</code> depending
on the number of models deployed:</p>
<table class='table'>
<tr><td><strong>Deployment</strong></td><td><strong>Environment variable value</strong></td></tr>
<tr><td>Single model</td><td>The path to the folder containing the model</td></tr>
<tr><td>Multiple models</td><td>The path to the folder containing all models. Models are located by name and version in this folder (<code>$MODEL_NAME/$VERSION</code>)</td></tr>
</table>


<p>To get the path to a file in a model, combine the environment variable
with the filename you're looking for. The filenames of the model files
are preserved during registration and deployment.</p>
<p>Single model example:</p><pre>model_path &lt;- file.path(Sys.getenv("AZUREML_MODEL_DIR"), "my_model.rds")
</pre>

<p>Multiple model example:</p><pre>model1_path &lt;- file.path(Sys.getenv("AZUREML_MODEL_DIR"), "my_model/1/my_model.rds")
</pre>



    
    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>

    

<p>The following example loads a previously registered environment from
your workspace and uses it for defining the inference config:</p><pre>ws &lt;- load_workspace_from_config()
deploy_env = get_environment(ws, name = "my_env", version = "1")
inference_config = inference_config(entry_script = "score.R", 
                                    environment = deploy_env)
</pre>

<p>You can then specify the inference config to <code><a href='deploy_model.html'>deploy_model()</a></code> to
deploy a web service.</p>
    
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p><code><a href='r_environment.html'>r_environment()</a></code>, <code><a href='deploy_model.html'>deploy_model()</a></code></p></div>
    

  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>

      <li><a href="#details">Details</a></li>

      <li><a href="#examples">Examples</a></li>

      <li><a href="#see-also">See also</a></li>
          </ul>

  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Himanshu Chandola, Billy Hu, Heemanshu Suri, Diondra Peck, AzureML R SDK Team, Microsoft.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


